{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=224, interpolation=bicubic, max_size=None, antialias=warn)\n",
       "    CenterCrop(size=(224, 224))\n",
       "    <function _convert_image_to_rgb at 0x00000237721670A0>\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "model, preprocess = clip.load(\"RN50\", device=device, download_root=None)\n",
    "model.eval()\n",
    "\n",
    "# This also provides a useful preprocessing pipeline for the images\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:27<00:00, 6222836.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n"
     ]
    }
   ],
   "source": [
    "# Class labels of CIFAR10\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Load the test set of CIFAR10 and add the preprocessing pipeline\n",
    "cifar10 = CIFAR10(root='./data', train=False, download=True, transform=preprocess)\n",
    "\n",
    "# Create a dataloader\n",
    "dl = DataLoader(cifar10, batch_size=64, num_workers=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 10]) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# let's start by using no prompt but simply the classname as sanity check\n",
    "template = 'An image of a {}'\n",
    "\n",
    "# The result is a tensor of shape (1024, 10),\n",
    "# since we have 10 classes and the feature dimension of the text encoder is 1024\n",
    "text_embedding = None\n",
    "\n",
    "# 1. Insert each classname into the template to create a prompt\n",
    "# 2. Tokenize the prompts with `clip.tokenize`\n",
    "tokens = clip.tokenize([template.format(cls) for cls in classes]).to(device)\n",
    "# we don't want to calculate gradient during evaluation\n",
    "with torch.no_grad():\n",
    "    # 3. Forward the result through the text encoder\n",
    "    text_embedding = model.encode_text(tokens)\n",
    "    # 4. Normalize the embedding\n",
    "    text_embedding = F.normalize(text_embedding, dim=-1).T\n",
    "\n",
    "print(text_embedding.shape, text_embedding.norm(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:15<00:00, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.71230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = len(cifar10)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # 1. Loop over the dataset\n",
    "    for inputs, targets in tqdm(dl):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # 2. Create visual embeddings with the image encoder\n",
    "        features = model.encode_image(inputs)\n",
    "        features = F.normalize(features, dim=-1)\n",
    "        \n",
    "        # 3. Calculate the cosine similarity between the image and text embeddings\n",
    "        logits = features @ text_embedding\n",
    "        \n",
    "        # 4. Count the number of correct predictions\n",
    "        preds = logits.argmax(1)\n",
    "        correct += (preds == targets).sum()\n",
    "\n",
    "print(f\"Accuracy: {correct / total: .5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Prompt | Accuracy | Comment            |\n",
    "|--------| --- |--------------------|\n",
    "| 'This is a {}.'  | 0.696 | not so good |\n",
    "| 'A {}'  | 0.672 | Poor result |\n",
    "| '{}'  | 0.708 | Could be better... |\n",
    "| 'This image contains {}' | 71.5 | Improvment, but not significantly better |\n",
    "| 'There is {}' | 71.5 | Improvment, but not significantly better |\n",
    "| 'a photo of a {}'  | 0.716 | better |\n",
    "| 'you can see a {}' | 0.716 | better |\n",
    "| 'A {} is in the picture' | 0.726 | better |\n",
    "| 'In this image you can see a {}' | 0.727 | Best result so far |\n",
    "| 'You can see a {} in this image' | 0.727 | Best result so far |\n",
    "| 'An {} is waiting' | 0.733 | best |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
